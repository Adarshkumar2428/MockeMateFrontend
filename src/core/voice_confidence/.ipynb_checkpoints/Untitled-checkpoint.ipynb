{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0cb13e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lang_chain/anaconda3/lib/python3.9/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/home/lang_chain/anaconda3/lib/python3.9/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator StandardScaler from version 1.2.2 when using version 1.4.1.post1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step\n",
      "['fear']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lang_chain/anaconda3/lib/python3.9/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator OneHotEncoder from version 1.2.2 when using version 1.4.1.post1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers as L\n",
    "from keras.layers import Input, Flatten, Dropout, Activation\n",
    "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "class Voice_confidence:\n",
    "    def __init__(self) -> None:\n",
    "        self.model_weights = 'CNN_model_weights.weights.h5'\n",
    "        self.model_encoder = 'encoder2.pickle'\n",
    "        self.model_scaler = 'scaler2.pickle'\n",
    "        self.expected_length  = 4\n",
    "        self.emotions1 = {1: 'Neutral', 2: 'Calm', 3: 'Happy', 4: 'Sad', 5: 'Angry', 6: 'Fear', 7: 'Disgust', 8: 'Surprise'}\n",
    "        \n",
    "        # Define the model architecture\n",
    "        self.model = tf.keras.Sequential([\n",
    "            L.Conv1D(512, kernel_size=5, strides=1, padding='same', activation='relu', input_shape=(1620, 1)),\n",
    "            L.BatchNormalization(),\n",
    "            L.MaxPool1D(pool_size=5, strides=2, padding='same'),\n",
    "            L.Conv1D(512, kernel_size=5, strides=1, padding='same', activation='relu'),\n",
    "            L.BatchNormalization(),\n",
    "            L.MaxPool1D(pool_size=5, strides=2, padding='same'),\n",
    "            Dropout(0.2),\n",
    "            L.Conv1D(256, kernel_size=5, strides=1, padding='same', activation='relu'),\n",
    "            L.BatchNormalization(),\n",
    "            L.MaxPool1D(pool_size=5, strides=2, padding='same'),\n",
    "            L.Conv1D(256, kernel_size=3, strides=1, padding='same', activation='relu'),\n",
    "            L.BatchNormalization(),\n",
    "            L.MaxPool1D(pool_size=5, strides=2, padding='same'),\n",
    "            Dropout(0.2),\n",
    "            L.Conv1D(128, kernel_size=3, strides=1, padding='same', activation='relu'),\n",
    "            L.BatchNormalization(),\n",
    "            L.MaxPool1D(pool_size=3, strides=2, padding='same'),\n",
    "            Dropout(0.2),\n",
    "            L.Flatten(),\n",
    "            L.Dense(512, activation='relu'),\n",
    "            L.BatchNormalization(),\n",
    "            L.Dense(8, activation='softmax')\n",
    "        ])\n",
    "        \n",
    "        # Load the model weights\n",
    "        self.model.load_weights(self.model_weights)\n",
    "\n",
    "    def load_pickle_file(self, pickle_path):\n",
    "        with open(pickle_path, 'rb') as f:\n",
    "            return pickle.load(f)\n",
    "\n",
    "    def zcr(self, data, frame_length, hop_length):\n",
    "        zcr = librosa.feature.zero_crossing_rate(y=data, frame_length=frame_length, hop_length=hop_length)\n",
    "        return np.squeeze(zcr)\n",
    "\n",
    "    def rmse(self, data, frame_length=2048, hop_length=512):\n",
    "        rmse = librosa.feature.rms(y=data, frame_length=frame_length, hop_length=hop_length)\n",
    "        return np.squeeze(rmse)\n",
    "\n",
    "    def mfcc(self, data, sr, frame_length=2048, hop_length=512, flatten: bool = True):\n",
    "        mfcc = librosa.feature.mfcc(y=data, sr=sr, n_mfcc=13, hop_length=hop_length)\n",
    "        return np.squeeze(mfcc.T) if not flatten else np.ravel(mfcc.T)\n",
    "    \n",
    "    def preprocess_audio(self, audio_data,sample_rate):\n",
    "        # Ensure audio is exactly `expected_length` seconds\n",
    "        target_length = int(sample_rate * self.expected_length)\n",
    "        if len(audio_data) < target_length:\n",
    "            # Pad with zeros to reach `expected_length` seconds\n",
    "            audio_data = np.pad(audio_data, (0, target_length - len(audio_data)), mode='constant')\n",
    "        elif len(audio_data) > target_length:\n",
    "            # Trim to `expected_length` seconds\n",
    "            audio_data = audio_data[:target_length]\n",
    "        return audio_data\n",
    "\n",
    "    def extract_features(self, data, sr=22050, frame_length=2048, hop_length=512):\n",
    "        # Extract individual features\n",
    "        zcr_result = self.zcr(data, frame_length, hop_length)\n",
    "        rmse_result = self.rmse(data, frame_length, hop_length)\n",
    "        mfcc_result = self.mfcc(data, sr, frame_length, hop_length, flatten=True)\n",
    "\n",
    "        # Concatenate features\n",
    "        combined_features = np.hstack((zcr_result, rmse_result, mfcc_result))\n",
    "\n",
    "        # Check total size\n",
    "        total_features = len(combined_features)\n",
    "\n",
    "        # Pad or truncate to ensure exactly 1620 features\n",
    "        if total_features < 1620:\n",
    "            combined_features = np.pad(combined_features, (0, 1620 - total_features), mode='constant')\n",
    "        elif total_features > 1620:\n",
    "            combined_features = combined_features[:1620]\n",
    "\n",
    "        # Reshape to (1, 1620)\n",
    "        combined_features = np.reshape(combined_features, newshape=(1, 1620))\n",
    "\n",
    "        return combined_features\n",
    "\n",
    "    def get_predict_feat(self, file_path):\n",
    "        data, sr = librosa.load(file_path, sr=None)\n",
    "        #Calculate duration of loaded audio in seconds\n",
    "        duration = len(data) / sr\n",
    "        # Preprocess audio to `expected_length`\n",
    "        data = self.preprocess_audio(data,sr)\n",
    "        features = self.extract_features(data, sr)\n",
    "        scaler = self.load_pickle_file(self.model_scaler)\n",
    "        scaled_features = scaler.transform(features)\n",
    "        return scaled_features\n",
    "\n",
    "    def prediction(self, path1):\n",
    "        res = self.get_predict_feat(path1)\n",
    "        # Reshape the features for the Conv1D model\n",
    "        res = res.reshape(res.shape[0], res.shape[1], 1)\n",
    "        # Make predictions\n",
    "        predictions = self.model.predict(res)\n",
    "        # Load the encoder to decode the prediction\n",
    "        encoder2 = self.load_pickle_file(self.model_encoder)\n",
    "        y_pred = encoder2.inverse_transform(predictions)\n",
    "        return y_pred[0]\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    voice = Voice_confidence()\n",
    "    audio = '03-01-07-01-01-01-01.wav'\n",
    "    print(len(audio))\n",
    "    print(voice.prediction('03-01-07-01-01-01-01.wav'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebec53d5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyaudio'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_23173/3267735336.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpyaudio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyaudio'"
     ]
    }
   ],
   "source": [
    "import pyaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04f2fe11",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = '03-01-07-01-01-01-01.wav'\n",
    "data,sr = librosa.load(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "437af0c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85345"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20825ac8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44100"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(22050 * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb0c402",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
