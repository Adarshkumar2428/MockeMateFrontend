{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0451e774",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lang_chain/anaconda3/lib/python3.9/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator StandardScaler from version 1.2.2 when using version 1.4.1.post1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['angry']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lang_chain/anaconda3/lib/python3.9/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator OneHotEncoder from version 1.2.2 when using version 1.4.1.post1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers as L\n",
    "from keras.layers import Input, Flatten, Dropout, Activation\n",
    "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
    "import librosa\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import  model_from_json\n",
    "class Voice_confidence:\n",
    "    def __init__(self) -> None:\n",
    "        self.model_weights = 'CNN_model_weights.weights.h5'\n",
    "        self.model_encoder = 'encoder2.pickle'\n",
    "        self.model_scaler = 'scaler2.pickle'\n",
    "        self.model_json = 'CNN_model.json'\n",
    "\n",
    "        json_file = open(self.model_json, 'r')\n",
    "        loaded_model_json = json_file.read()\n",
    " \n",
    "        self.model = model_from_json(loaded_model_json)\n",
    "        \n",
    "        # Load the model weights\n",
    "        self.model.load_weights(self.model_weights)\n",
    "\n",
    "    def load_pickle_file(self, pickle_path):\n",
    "        with open(pickle_path, 'rb') as f:\n",
    "            return pickle.load(f)\n",
    "\n",
    "    def zcr(self, data, frame_length, hop_length):\n",
    "        zcr = librosa.feature.zero_crossing_rate(y=data, frame_length=frame_length, hop_length=hop_length)\n",
    "        return np.squeeze(zcr)\n",
    "\n",
    "    def rmse(self, data, frame_length=2048, hop_length=512):\n",
    "        rmse = librosa.feature.rms(y=data, frame_length=frame_length, hop_length=hop_length)\n",
    "        return np.squeeze(rmse)\n",
    "\n",
    "    def mfcc(self, data, sr, frame_length=2048, hop_length=512, flatten: bool = True):\n",
    "        mfcc = librosa.feature.mfcc(y=data, sr=sr, n_mfcc=13, hop_length=hop_length)\n",
    "        return np.squeeze(mfcc.T) if not flatten else np.ravel(mfcc.T)\n",
    "\n",
    "    def extract_features(self, data, sr=22050, frame_length=2048, hop_length=512):\n",
    "        # Extract individual features\n",
    "        zcr_result = self.zcr(data, frame_length, hop_length)\n",
    "        rmse_result = self.rmse(data, frame_length, hop_length)\n",
    "        mfcc_result = self.mfcc(data, sr, frame_length, hop_length, flatten=True)\n",
    "\n",
    "        # Concatenate features\n",
    "        combined_features = np.hstack((zcr_result, rmse_result, mfcc_result))\n",
    "\n",
    "        # Check total size\n",
    "        total_features = len(combined_features)\n",
    "\n",
    "        # Pad or truncate to ensure exactly 1620 features\n",
    "        if total_features < 1620:\n",
    "            combined_features = np.pad(combined_features, (0, 1620 - total_features), mode='constant')\n",
    "        elif total_features > 1620:\n",
    "            combined_features = combined_features[:1620]\n",
    "\n",
    "        # Reshape to (1, 1620)\n",
    "        combined_features = np.reshape(combined_features, newshape=(1, 1620))\n",
    "\n",
    "        return combined_features\n",
    "\n",
    "    def et_predict_feat(self, file_path):\n",
    "        data, sr = librosa.load(file_path, sr=None)\n",
    "        features = self.extract_features(data, sr)\n",
    "        scaler = self.load_pickle_file(self.model_scaler)\n",
    "        scaled_features = scaler.transform(features)\n",
    "        return scaled_features\n",
    "\n",
    "    def prediction(self, path1):\n",
    "        res = self.et_predict_feat(path1)\n",
    "        res = res.reshape(res.shape[0], res.shape[1], 1)\n",
    "        # Make predictions\n",
    "        predictions = self.model.predict(res)\n",
    "     \n",
    "    \n",
    "        encoder2 = self.load_pickle_file(self.model_encoder)\n",
    "        y_pred = encoder2.inverse_transform(predictions)\n",
    "        return y_pred[0]\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    voice = Voice_confidence()\n",
    "    print(voice.prediction('1001_DFA_ANG_XX.wav'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0086158b",
   "metadata": {},
   "source": [
    "segmentation for the clips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5f5777e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9906/727660529.py:1: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  data,sr = librosa.load(\"WhatsApp Audio 2024-07-11 at 12.37.05 PM.mp4\")\n",
      "/home/lang_chain/anaconda3/lib/python3.9/site-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
     ]
    }
   ],
   "source": [
    "data,sr = librosa.load(\"sample\")\n",
    "segment_samples = int(2.5 * sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8984cd80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55125, 221088)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_samples = len(data)\n",
    "segment_samples,total_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4cd9aa13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55125\n",
      "110250\n",
      "165375\n",
      "220500\n",
      "275625\n"
     ]
    }
   ],
   "source": [
    "for start in range(0, total_samples, segment_samples):\n",
    "    end = start + segment_samples\n",
    "    print(end)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685abb80",
   "metadata": {},
   "source": [
    "{1: 'Neutral', 2: 'Calm', 3: 'Happy', 4: 'Sad', 5: 'Angry', 6: 'Fear', 7: 'Disgust', 8: 'Surprise'}\n",
    "        \n",
    "data = {1: 'Calm', 2: 'Calm', 3: 'Confident', 4: 'Under confident', 5: 'Confident', 6: 'under confident', 7: 'under confident', 8: 'Confiddent'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4dd18f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9906/3311293452.py:89: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  data, sr = librosa.load(audio_file, sr=None)\n",
      "/home/lang_chain/anaconda3/lib/python3.9/site-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
      "/home/lang_chain/anaconda3/lib/python3.9/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator StandardScaler from version 1.2.2 when using version 1.4.1.post1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284ms/step\n",
      "y_pred values: [['fear']]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "y_pred values: [['sad']]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "y_pred values: [['sad']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lang_chain/anaconda3/lib/python3.9/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator OneHotEncoder from version 1.2.2 when using version 1.4.1.post1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/home/lang_chain/anaconda3/lib/python3.9/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator StandardScaler from version 1.2.2 when using version 1.4.1.post1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/home/lang_chain/anaconda3/lib/python3.9/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator OneHotEncoder from version 1.2.2 when using version 1.4.1.post1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/home/lang_chain/anaconda3/lib/python3.9/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator StandardScaler from version 1.2.2 when using version 1.4.1.post1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/home/lang_chain/anaconda3/lib/python3.9/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator OneHotEncoder from version 1.2.2 when using version 1.4.1.post1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/home/lang_chain/anaconda3/lib/python3.9/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator StandardScaler from version 1.2.2 when using version 1.4.1.post1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "y_pred values: [['sad']]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "y_pred values: [['fear']]\n",
      "['Under confident', 'Under confident', 'Under confident', 'Under confident', 'Under confident']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lang_chain/anaconda3/lib/python3.9/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator OneHotEncoder from version 1.2.2 when using version 1.4.1.post1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/home/lang_chain/anaconda3/lib/python3.9/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator StandardScaler from version 1.2.2 when using version 1.4.1.post1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/home/lang_chain/anaconda3/lib/python3.9/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator OneHotEncoder from version 1.2.2 when using version 1.4.1.post1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import librosa\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import model_from_json\n",
    "\n",
    "class Voice_confidence:\n",
    "    def __init__(self):\n",
    "        self.model_weights = 'CNN_model_weights.weights.h5'\n",
    "        self.model_encoder = 'encoder2.pickle'\n",
    "        self.model_scaler = 'scaler2.pickle'\n",
    "        self.model_json = 'CNN_model.json'\n",
    "\n",
    "        self.emotion_mapping = {\n",
    "            'neutral': 'Calm',\n",
    "            'calm': 'Calm',\n",
    "            'happy': 'Confident',\n",
    "            'sad': 'Under confident',\n",
    "            'angry': 'Confident',\n",
    "            'fear': 'Under confident',\n",
    "            'disgust': 'Under confident',\n",
    "            'surprise': 'Confident'\n",
    "        }\n",
    "        # Load model architecture from JSON\n",
    "        json_file = open(self.model_json, 'r')\n",
    "        loaded_model_json = json_file.read()\n",
    "        json_file.close()\n",
    "        self.model = model_from_json(loaded_model_json)\n",
    "        \n",
    "        # Load the model weights\n",
    "        self.model.load_weights(self.model_weights)\n",
    "\n",
    "    def load_pickle_file(self, pickle_path):\n",
    "        with open(pickle_path, 'rb') as f:\n",
    "            return pickle.load(f)\n",
    "\n",
    "    def zcr(self, data, frame_length, hop_length):\n",
    "        zcr = librosa.feature.zero_crossing_rate(y=data, frame_length=frame_length, hop_length=hop_length)\n",
    "        return np.squeeze(zcr)\n",
    "\n",
    "    def rmse(self, data, frame_length=2048, hop_length=512):\n",
    "        rmse = librosa.feature.rms(y=data, frame_length=frame_length, hop_length=hop_length)\n",
    "        return np.squeeze(rmse)\n",
    "\n",
    "    def mfcc(self, data, sr, frame_length=2048, hop_length=512, flatten=True):\n",
    "        mfcc = librosa.feature.mfcc(y=data, sr=sr, n_mfcc=13, hop_length=hop_length)\n",
    "        return np.squeeze(mfcc.T) if not flatten else np.ravel(mfcc.T)\n",
    "\n",
    "    def extract_features(self, data, sr=22050, frame_length=2048, hop_length=512):\n",
    "        zcr_result = self.zcr(data, frame_length, hop_length)\n",
    "        rmse_result = self.rmse(data, frame_length, hop_length)\n",
    "        mfcc_result = self.mfcc(data, sr, frame_length, hop_length, flatten=True)\n",
    "        \n",
    "        combined_features = np.hstack((zcr_result, rmse_result, mfcc_result))\n",
    "        total_features = len(combined_features)\n",
    "        \n",
    "        if total_features < 1620:\n",
    "            combined_features = np.pad(combined_features, (0, 1620 - total_features), mode='constant')\n",
    "        elif total_features > 1620:\n",
    "            combined_features = combined_features[:1620]\n",
    "        \n",
    "        combined_features = np.reshape(combined_features, newshape=(1, 1620))\n",
    "        return combined_features\n",
    "\n",
    "    def et_predict_feat(self, data):\n",
    "        features = self.extract_features(data)\n",
    "        scaler = self.load_pickle_file(self.model_scaler)\n",
    "        scaled_features = scaler.transform(features)\n",
    "        return scaled_features\n",
    "\n",
    "    def prediction(self, data):\n",
    "        res = self.et_predict_feat(data)\n",
    "        res = res.reshape(res.shape[0], res.shape[1], 1)\n",
    "        predictions = self.model.predict(res)\n",
    "        encoder2 = self.load_pickle_file(self.model_encoder)\n",
    "        y_pred = encoder2.inverse_transform(predictions)\n",
    "\n",
    "        # Debugging prints\n",
    "        print(\"y_pred values:\", y_pred)\n",
    "\n",
    "        predicted_label = y_pred[0][0] \n",
    "        if predicted_label in self.emotion_mapping:\n",
    "            original_emotion = self.emotion_mapping[predicted_label]\n",
    "\n",
    "            return original_emotion\n",
    "        else:\n",
    "            return \"Unknown Emotion\"\n",
    "\n",
    "    def process_audio_file(self, audio_file, clip_duration=2.5):\n",
    "        data, sr = librosa.load(audio_file, sr=None) \n",
    "        clip_length = int(clip_duration * sr)\n",
    "        predictions = []\n",
    "\n",
    "        # Segment the audio into clips\n",
    "        for i in range(0, len(data), clip_length):\n",
    "            segment = data[i:i+clip_length]\n",
    "            if len(segment) < clip_length:\n",
    "                # Pad the segment if it's shorter than the desired clip length\n",
    "                segment = np.pad(segment, (0, clip_length - len(segment)), mode='constant')\n",
    "\n",
    "            # Perform prediction on the segment\n",
    "            prediction = self.prediction(segment)\n",
    "            predictions.append(prediction)\n",
    "\n",
    "        return predictions\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    voice = Voice_confidence()\n",
    "    audio_file = 'sample'  \n",
    "    predictions = voice.process_audio_file(audio_file)\n",
    "    print(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8d3597",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
